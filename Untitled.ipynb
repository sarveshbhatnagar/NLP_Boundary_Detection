{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import multiprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordsFeature:\n",
    "    def __init__(self, df, label_encoder):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.label_encoder = label_encoder\n",
    "        # self.train_le()\n",
    "\n",
    "    def get_next_word(self, index, orignal=False):\n",
    "        \"\"\"\n",
    "        Given an index of a word, returns the next word from the dataframe\n",
    "        params:\n",
    "            index: int\n",
    "        returns:\n",
    "            word: str\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if orignal:\n",
    "                return self.df.iloc[index + 1][1]\n",
    "            return self.label_encoder.transform([self.df.iloc[index + 1][1]])[0]\n",
    "        except IndexError:\n",
    "            if orignal:\n",
    "                return \"<END>\"\n",
    "            return self.label_encoder.transform([\"<END>\"])[0]\n",
    "        except ValueError:\n",
    "            # Returning -1 for unseen words\n",
    "            return -1\n",
    "\n",
    "    def get_prev_word(self, index, orignal=False):\n",
    "        \"\"\"\n",
    "        Given an index of a word, returns the word before '.' from the dataframe\n",
    "        params:\n",
    "            index: int\n",
    "        returns:\n",
    "            word: str\n",
    "        \"\"\"\n",
    "        try:\n",
    "\n",
    "            word = self.df.iloc[index][1]\n",
    "            if word[-1] == \".\":\n",
    "                if orignal:\n",
    "                    return word[:-1]\n",
    "                return self.label_encoder.transform([word[:-1]])[0]\n",
    "            else:\n",
    "                # NOT A PERIOD\n",
    "                # I think it would be better to return a <NAP> token\n",
    "                # This might also help in cleaning the data\n",
    "                # If orignal is true return word as is...\n",
    "                if orignal:\n",
    "                    return word\n",
    "#                 return self.label_encoder.transform([word])[0]\n",
    "                return self.label_encoder.transform([\"<NAP>\"])[0]\n",
    "        except ValueError:\n",
    "            # Returning -1 for unseen words\n",
    "            return -1\n",
    "        except IndexError:\n",
    "            if orignal:\n",
    "                return \"<START>\"\n",
    "            return self.label_encoder.transform([\"<START>\"])[0]\n",
    "\n",
    "    def lt_3(self, index):\n",
    "        \"\"\"\n",
    "        Given an index of a word, returns True if length of word before '.' is < 3 in the dataframe\n",
    "        params:\n",
    "            index: int\n",
    "        returns:\n",
    "            word: str\n",
    "        \"\"\"\n",
    "        word = self.get_prev_word(index, orignal=True)\n",
    "        return len(word) < 3\n",
    "\n",
    "    def is_cap_word(self, word):\n",
    "        \"\"\"\n",
    "        Given an index of a word, returns True if the word is capitalized in the dataframe\n",
    "        params:\n",
    "            index: int (index of word)\n",
    "            i: int\n",
    "        returns:\n",
    "            is_capital: bool\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return word[0].isupper()\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def actual_len(self, index):\n",
    "        \"\"\"\n",
    "        Returns the actual length of the previous word\n",
    "        \"\"\"\n",
    "        word = self.get_prev_word(index, orignal=True)\n",
    "        return len(word)\n",
    "    \n",
    "    def gt_x(self, index,x=4):\n",
    "        \"\"\"\n",
    "        Given an index of a word, returns True if length of word before '.' is < 3 in the dataframe\n",
    "        params:\n",
    "            index: int\n",
    "        returns:\n",
    "            word: str\n",
    "        \"\"\"\n",
    "        word = self.get_prev_word(index, orignal=True)\n",
    "        return len(word) > x\n",
    "\n",
    "    def get_average_len(self, index):\n",
    "        \"\"\"\n",
    "        Returns the average length of the previous word and next word\n",
    "        \"\"\"\n",
    "        prev_word = self.get_prev_word(index, orignal=True)\n",
    "        next_word = self.get_next_word(index, orignal=True)\n",
    "        return (len(prev_word) + len(next_word)) / 2\n",
    "\n",
    "    def get_avg_len(self, index, window=4):\n",
    "        \"\"\"\n",
    "        Given a window, returns the average length of the words in the window\n",
    "        (before current word only)\n",
    "\n",
    "        params:\n",
    "            index: int\n",
    "            window: int (default 4)\n",
    "        returns:\n",
    "            avg_len: float\n",
    "        \"\"\"\n",
    "        if index < 4:\n",
    "            words = [len(self.get_prev_word(i, orignal=True)) for i in range(1, index)]\n",
    "        else:\n",
    "            words = [\n",
    "                len(self.get_prev_word(index - i, orignal=True)) for i in range(window)\n",
    "            ]\n",
    "        try:\n",
    "            return sum(words) / len(words)\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def get_feature(self, index, nof=5):\n",
    "        \"\"\"\n",
    "        Given an index, return corresponding features\n",
    "        params:\n",
    "            index: int\n",
    "        returns:\n",
    "            feature: list (prev word, next word, left_word<3, left_is_cap, right_is_cap, label)\n",
    "        \"\"\"\n",
    "        feature = []\n",
    "        # word to the left\n",
    "        if nof > 0:\n",
    "            feature.append(self.get_prev_word(index))\n",
    "        # word to the right\n",
    "        if nof > 1:\n",
    "            feature.append(self.get_next_word(index))\n",
    "        # length of word to the left > 3\n",
    "        if nof > 2:\n",
    "            feature.append(self.lt_3(index))\n",
    "        # Left word is capitalized\n",
    "        if nof > 3:\n",
    "            feature.append(self.is_cap_word(self.get_prev_word(index, orignal=True)))\n",
    "        # Right word is capitalized\n",
    "        if nof > 4:\n",
    "            feature.append(self.is_cap_word(self.get_next_word(index, orignal=True)))\n",
    "\n",
    "        # More three features\n",
    "        if nof > 5:\n",
    "#             feature.append(self.gt_x(index,x=4))\n",
    "#             feature.append(self.gt_x(index,x=5))\n",
    "#             feature.append(self.gt_x(index,x=6))\n",
    "#             feature.append(self.gt_x(index,x=7))\n",
    "            feature.append(self.get_avg_len(index))\n",
    "        if nof > 6:\n",
    "            feature.append(self.get_average_len(index))\n",
    "        if nof > 7:\n",
    "            feature.append(self.actual_len(index))\n",
    "\n",
    "        # Finally add label token\n",
    "        feature.append(self.df[2][index])\n",
    "        return feature\n",
    "\n",
    "    def train_le(self):\n",
    "        \"\"\"\n",
    "        It trains label encoder with the appropriate data.\n",
    "        \"\"\"\n",
    "\n",
    "        lisa = [self.get_prev_word(i, orignal=True) for i in range(len(self.df))]\n",
    "        lisb = [self.get_next_word(i, orignal=True) for i in range(len(self.df))]\n",
    "        lis = lisa + lisb\n",
    "        lis.append(\"<NAP>\")\n",
    "        lis.append(\"<START>\")\n",
    "        return self.label_encoder.fit(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarvesh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1cca88a00308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mwf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordsFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_le\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mnf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'([a-zA-Z0-9\\)%.\"]+)([.]+)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-1fb358794320>\u001b[0m in \u001b[0;36mtrain_le\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mlisa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prev_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morignal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mlisb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morignal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0mlis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlisa\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlisb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mlis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<NAP>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-1fb358794320>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mlisa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prev_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morignal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mlisb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morignal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0mlis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlisa\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlisb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mlis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<NAP>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-1fb358794320>\u001b[0m in \u001b[0;36mget_next_word\u001b[0;34m(self, index, orignal)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0morignal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser(description=\"Sentence Boundary Detection\")\n",
    "# parser.add_argument(\"train\", help=\"Training file\")\n",
    "# parser.add_argument(\"test\", help=\"Test file\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "train_file = \"SBD.train\"\n",
    "test_file = \"SBD.test\"\n",
    "# train_file = args.train\n",
    "# test_file = args.test\n",
    "\n",
    "# Check if train file and test file exists\n",
    "# if not os.path.isfile(train_file) or os.path.isfile(test_file):\n",
    "#     print(\"Training or Testing file does not exist\")\n",
    "#     sys.exit(1)\n",
    "\n",
    "# Read the training file\n",
    "f = pd.read_csv(train_file, sep=r\"\\s\", header=None)\n",
    "f = f.drop(0, axis=1)\n",
    "\n",
    "# Resultant file\n",
    "#        1    2\n",
    "# 0     On  TOK\n",
    "# 1   June  TOK\n",
    "# 2      4  TOK\n",
    "# 3      ,  TOK\n",
    "# 4  after  TOK\n",
    "\n",
    "wf = WordsFeature(f, label_encoder=LabelEncoder())\n",
    "le = wf.train_le()\n",
    "nf = f[1].str.extract(r'([a-zA-Z0-9\"]+)([.]+)')\n",
    "\n",
    "nf.dropna(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = WordsFeature(f, label_encoder=LabelEncoder())\n",
    "le = wf.train_le()\n",
    "# nf = f[1].str.extract(r'([a-zA-Z0-9.%\\\"]+)([.])')\n",
    "nf = f[1].str.contains(r'\\.$')\n",
    "\n",
    "# nf.dropna(inplace=True)\n",
    "# aind = set(nf.index)\n",
    "# nf = f[1].str.extract(r\"([a-zA-Z0-9]+)([.])([a-zA-Z0-9,-]+)\")\n",
    "# nf.dropna(inplace=True)\n",
    "# first_last = set(nf.index)\n",
    "# ind = f[2][aind - first_last].index\n",
    "# ind = f[2][aind].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = f[nf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17227"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32        NEOS\n",
       "56         EOS\n",
       "86        NEOS\n",
       "100        EOS\n",
       "108       NEOS\n",
       "          ... \n",
       "297193     EOS\n",
       "297203    NEOS\n",
       "297216     EOS\n",
       "297236     EOS\n",
       "297254     EOS\n",
       "Name: 2, Length: 17227, dtype: object"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280028"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f[f[2]==\"TOK\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17227"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f) - len(f[f[2]==\"TOK\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_df = f.index.isin(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "fff = f[~bad_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [1, 2]\n",
       "Index: []"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fff[fff[2] == \"EOS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffi = f[bad_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On</td>\n",
       "      <td>TOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>June</td>\n",
       "      <td>TOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>TOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,</td>\n",
       "      <td>TOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>after</td>\n",
       "      <td>TOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297249</th>\n",
       "      <td>a</td>\n",
       "      <td>TOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297250</th>\n",
       "      <td>total</td>\n",
       "      <td>TOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297251</th>\n",
       "      <td>of</td>\n",
       "      <td>TOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297252</th>\n",
       "      <td>$</td>\n",
       "      <td>TOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297253</th>\n",
       "      <td>200</td>\n",
       "      <td>TOK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280028 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1    2\n",
       "0          On  TOK\n",
       "1        June  TOK\n",
       "2           4  TOK\n",
       "3           ,  TOK\n",
       "4       after  TOK\n",
       "...       ...  ...\n",
       "297249      a  TOK\n",
       "297250  total  TOK\n",
       "297251     of  TOK\n",
       "297252      $  TOK\n",
       "297253    200  TOK\n",
       "\n",
       "[280028 rows x 2 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffi[ffi[2] == \"TOK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilst = list(nf[0].index)\n",
    "pool = multiprocessing.Pool()\n",
    "pool = multiprocessing.Pool(processes=4)\n",
    "lst = pool.map(wf.get_feature, ilst)\n",
    "pool.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now have list containing features. We will now convert this to pandas dataframe.\n",
    "\n",
    "# Two methods to move forward, either simply discard TOK and move with just EOS and NEOS\n",
    "# or we can keep TOK and move with EOS and NEOS\n",
    "# We will use the second method, if it works then good else we will try the first method.\n",
    "\n",
    "# Try 1\n",
    "# keep features only\n",
    "x = [lst[i][:-1] for i in range(len(lst))]\n",
    "y = [lst[i][-1] for i in range(len(lst))]\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(x, y)\n",
    "features = 5\n",
    "# We can save dtree as pickle...\n",
    "with open(\"dtree{}.pkl\".format(features), \"wb\") as dfile:\n",
    "    pickle.dump(clf, dfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarvesh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000\n",
      "51000\n",
      "46000\n",
      "91000\n",
      "139000\n",
      "140000\n",
      "143000\n",
      "116000\n",
      "0.8781965006729475\n"
     ]
    }
   ],
   "source": [
    "# Test phase\n",
    "\n",
    "td = pd.read_csv(test_file, sep=r\"\\s\", header=None)\n",
    "td = td.drop(0, axis=1)\n",
    "twf = WordsFeature(td, le)\n",
    "tnf = td[1].str.extract(r'([a-zA-Z0-9\"]+)([.]+)')\n",
    "tnf.dropna(inplace=True)\n",
    "tilst = list(tnf.index)\n",
    "tpool = multiprocessing.Pool()\n",
    "tpool = multiprocessing.Pool(processes=4)\n",
    "tlst = tpool.map(twf.get_feature, tilst)\n",
    "tpool.close()\n",
    "\n",
    "# Splitting into training and testing data...\n",
    "xt = [tlst[i][:-1] for i in range(len(tlst))]\n",
    "yt = [tlst[i][-1] for i in range(len(tlst))]\n",
    "\n",
    "preds = clf.predict(xt)\n",
    "\n",
    "print(accuracy_score(yt, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 features: 87.81%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More features: 87.21% Actually reduces accuracy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed NAP tokens... All features... I think this might increase accuracy as it will become aware of the word.\n",
    "# Wrong hypothesis.\n",
    "# It actually increases the accuracy for some reason?...\n",
    "# I think label encoder is causing problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using get_avg_len and gt_x with x=6\n",
    "# It might increase the accuracy\n",
    "# Also I think the accuracy is reduced due to 3 class classification instead of 2...\n",
    "# 87.31%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = f[1].str.extract(r'([a-zA-Z0-9])([.])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "aind = set(nf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18951"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = f[2][nf.index] == \"TOK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>U</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296267</th>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296270</th>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296569</th>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296939</th>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297051</th>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2031 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1\n",
       "815     U  .\n",
       "2332    2  .\n",
       "2616    2  .\n",
       "2637    2  .\n",
       "2776    2  .\n",
       "...    .. ..\n",
       "296267  4  .\n",
       "296270  2  .\n",
       "296569  1  .\n",
       "296939  0  .\n",
       "297051  1  .\n",
       "\n",
       "[2031 rows x 2 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf[z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = f[1].str.extract(r'([a-zA-Z0-9]+)([.])([a-zA-Z0-9,-]+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = f[2][nf.index] == \"TOK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>U</td>\n",
       "      <td>.</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>302</td>\n",
       "      <td>.</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296267</th>\n",
       "      <td>44</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296270</th>\n",
       "      <td>42</td>\n",
       "      <td>.</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296569</th>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296939</th>\n",
       "      <td>30</td>\n",
       "      <td>.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297051</th>\n",
       "      <td>21</td>\n",
       "      <td>.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2031 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  1   2\n",
       "815       U  .   S\n",
       "2332      2  .   5\n",
       "2616      2  .   2\n",
       "2637      2  .   1\n",
       "2776    302  .   6\n",
       "...     ... ..  ..\n",
       "296267   44  .   1\n",
       "296270   42  .   6\n",
       "296569    1  .  21\n",
       "296939   30  .   5\n",
       "297051   21  .   4\n",
       "\n",
       "[2031 rows x 3 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf[z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_last=set(nf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15944"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aind - first_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([196610, 262146, 131076, 262148, 131086, 196628, 262170, 196639,\n",
       "                32, 262180,\n",
       "            ...\n",
       "             65501, 131040,  65505, 262116, 196586, 196590, 131055, 131056,\n",
       "            196603,  65533],\n",
       "           dtype='int64', length=15944)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[2][aind-first_last].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda99bcb4b0a0be4110a87e42072b64ae25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
